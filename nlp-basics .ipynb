{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WyENSwOKlzjJ",
        "VZCQLFaCrllS",
        "YldM7MPkq9xR",
        "K0lFaEMTmIrC",
        "IjZrx7ZrgUSp",
        "ij6xV95HiuAd",
        "IW6OnF6waAoz",
        "UiI1ULVQQ9AC",
        "vByInPCMn1_R"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "اردو- 38 حروف"
      ],
      "metadata": {
        "id": "OCFMcSDfpOht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ا ب پ ت ٹ ث ج چ ح خ د ڈ ذ ر ڑ ز ژ س ش ص ض ط ظ ع غ ل م ن و ھ ئ ی ے\n",
        "\n",
        "ا با پا تا تا ٹا ثا جا چا حا خا دا ڈا ذا را ڑا زا ژا سا شا صا ضا طا ظا عا غا فا قا کا گا لا ما نا وا ھا ئا یا ے\n"
      ],
      "metadata": {
        "id": "TAsB1-pxvHVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week1_Task1_Identify Joiner and Non Joiner in urdu letters"
      ],
      "metadata": {
        "id": "WyENSwOKlzjJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Joiner Letters:**  \n",
        "- ب  \n",
        "- پ  \n",
        "- ت  \n",
        "- ٹ  \n",
        "- ث  \n",
        "- ج  \n",
        "- چ  \n",
        "- ح  \n",
        "- خ  \n",
        "- س  \n",
        "- ش  \n",
        "- ص  \n",
        "- ض  \n",
        "- ط  \n",
        "- ظ  \n",
        "- ع  \n",
        "- غ  \n",
        "- ف  \n",
        "- ق  \n",
        "- ک  \n",
        "- گ  \n",
        "- ل  \n",
        "- م  \n",
        "- ن  \n",
        "- ھ  \n",
        "- ئ  \n",
        "- ی  \n",
        "\n",
        "### **Non-Joiner Letters:**  \n",
        "- آ  \n",
        "- د  \n",
        "- ڈ  \n",
        "- ذ  \n",
        "- ر  \n",
        "- ڑ  \n",
        "- ز  \n",
        "- ژ  \n",
        "- و  \n",
        "- ا  \n",
        "- ے  "
      ],
      "metadata": {
        "id": "Tuy-uf1MooXJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week1_Task2_Calulate frequency of each word in paragrapgh, identify type and tokens of sentence"
      ],
      "metadata": {
        "id": "VZCQLFaCrllS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tp22uuyTJlz1"
      },
      "outputs": [],
      "source": [
        "def file():\n",
        "  file_name = input(\"Enter File name: \")\n",
        "  try:\n",
        "    fhand = open(file_name, \"r\")\n",
        "  except:\n",
        "    print(\"File not found.\")\n",
        "  return fhand"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_frequency(fhand):\n",
        "    word_frq = dict()\n",
        "    for line in fhand:\n",
        "            cleaned_text = \"\"\n",
        "            for char in line:\n",
        "                if char.isalnum() or char.isspace():  # Allow only alphanumeric characters and spaces\n",
        "                    cleaned_text += char\n",
        "            words = cleaned_text.split()\n",
        "            for word in words:\n",
        "                if word in word_frq:\n",
        "                 word_frq[word] = word_frq[word] + 1\n",
        "                else:\n",
        "                    word_frq[word]=1\n",
        "    return word_frq"
      ],
      "metadata": {
        "id": "3Z_9j-MyKNip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_tokens_and_types(word_frq):\n",
        "  token = 0\n",
        "  type = 0  # Unique\n",
        "  for w,f in word_frq.items():\n",
        "    token += f\n",
        "    type += 1\n",
        "\n",
        "  return token, type"
      ],
      "metadata": {
        "id": "mww8fDpDLt-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_word_frequency(word_frq):\n",
        "    print(f\"{'Word':<20}{'Frequency':<10}\")\n",
        "    print(\"-\" * 30)\n",
        "    for word, frequency in word_frq.items():\n",
        "        print(f\"{word:<20}{frequency:<10}\")"
      ],
      "metadata": {
        "id": "QQIlR4gFNn3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fhand = file()\n",
        "word_frq = get_word_frequency(fhand)\n",
        "tokens,types = calculate_tokens_and_types(word_frq)\n",
        "print(\"Tokens: \",tokens)\n",
        "print(\"Types: \",types)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO1upIfiMpBC",
        "outputId": "ac123ace-c5ce-4966-cb2d-de050d7f290b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter File name: urdu.txt\n",
            "Tokens:  150\n",
            "Types:  95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_word_frequency(word_frq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hv5-FaWNZwS",
        "outputId": "c5c5a34d-667a-4f51-c87b-0b6f3f451ed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Frequency \n",
            "------------------------------\n",
            "یکنالوجی            1         \n",
            "کی                  3         \n",
            "ترقی                1         \n",
            "ٹیکنالوجی           4         \n",
            "نے                  4         \n",
            "پچھلے               1         \n",
            "چند                 1         \n",
            "سالوں               1         \n",
            "میں                 6         \n",
            "ہماری               2         \n",
            "زندگی               1         \n",
            "کو                  4         \n",
            "مکمل                1         \n",
            "طور                 1         \n",
            "پر                  1         \n",
            "بدل                 2         \n",
            "دیا                 4         \n",
            "ہے                  6         \n",
            "موبائل              1         \n",
            "فون                 1         \n",
            "کمپیوٹر             1         \n",
            "اور                 6         \n",
            "انٹرنیٹ             1         \n",
            "جیسے                2         \n",
            "آلات                1         \n",
            "دنیا                3         \n",
            "ایک                 1         \n",
            "گلوبل               1         \n",
            "ولیج                1         \n",
            "تبدیل               1         \n",
            "کر                  3         \n",
            "آج                  1         \n",
            "ہم                  2         \n",
            "کسی                 2         \n",
            "بھی                 3         \n",
            "جگہ                 1         \n",
            "بیٹھ                1         \n",
            "کے                  7         \n",
            "کونے                1         \n",
            "سے                  2         \n",
            "رابطہ               1         \n",
            "سکتے                1         \n",
            "ہیں                 2         \n",
            "تعلیم               1         \n",
            "میدان               1         \n",
            "آن                  1         \n",
            "لائن                1         \n",
            "کلاسز               1         \n",
            "ای                  2         \n",
            "لرننگ               1         \n",
            "طلبہ                1         \n",
            "لیے                 1         \n",
            "علم                 1         \n",
            "کا                  4         \n",
            "حصول                1         \n",
            "آسان                2         \n",
            "بنا                 2         \n",
            "صحت                 1         \n",
            "شعبے                1         \n",
            "جدید                1         \n",
            "مشینیں              1         \n",
            "استعمال             2         \n",
            "پیچیدہ              1         \n",
            "بیماریوں            1         \n",
            "علاج                1         \n",
            "ممکن                1         \n",
            "ہو                  1         \n",
            "گیا                 1         \n",
            "کاروبار             1         \n",
            "کامرس               1         \n",
            "خرید                1         \n",
            "و                   1         \n",
            "فروخت               1         \n",
            "طریقے               1         \n",
            "تاہم                1         \n",
            "کچھ                 1         \n",
            "منفی                1         \n",
            "پہلو                1         \n",
            "کہ                  1         \n",
            "وقت                 1         \n",
            "ضیاع                1         \n",
            "لوگوں               1         \n",
            "ذاتی                1         \n",
            "رابطے               1         \n",
            "کمی                 1         \n",
            "اگر                 1         \n",
            "صحیح                1         \n",
            "متوازن              1         \n",
            "کریں                1         \n",
            "تو                  1         \n",
            "یہ                  1         \n",
            "زندگیوں             1         \n",
            "مزید                1         \n",
            "بہتر                1         \n",
            "سکتی                1         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week1_Task5_Write an Urdu Paragraph"
      ],
      "metadata": {
        "id": "YldM7MPkq9xR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ٹیکنالوجئ کی ترقی:\n",
        "ٹیکنالوجی نےپچھلےچندسالوں میں ہماری زندگی کو مکمل طورپر بدل دیا ہے۔موبائل فون، کمپیوٹر،اور انٹرنیٹ جیسے آلات نے دنیا کو ایک گلوبل ولیج میں تبدیل کر دیا ہے۔ آج ہم کسی بھی جگہ بیٹھ کر دنیا کے کسی بھی کونے سے رابطہ کر سکتے ہیں۔ تعلیم کےمیدان میں آن لائن کلاسز ای لرننگ نے طلبہ کے لیے علم کا حصول آسان بنا دیا ہے۔ صحت کے شعبے میں جدید مشینیں اور ٹینکالوجی کے استعمال سے پیچیدہ بیماریوں کا علاج ممکن ہو گیا ہے۔ کاروبار کی دنیا میں ای کامرس نی خریدوفروخت کے طریقے کو بدل دیا ہے۔\n",
        " تاہم، ٹیکنالوجی کے کچھ منفی پہلو بھی ہیں، جیسے کہ وقت کا ضیاع اور لوگوں میں ذاتی رابطے کی کمی۔ اگر ہم ٹیکنالوجی کا صحیح اور متوازن استعمال کریں، تو یہ ہماری زندگیوں کو مزید بہتر اور آسان بنا سکتی ہے۔\n"
      ],
      "metadata": {
        "id": "V6DOMud6t5Mm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week2_Task2_Calculate average length of urdu words"
      ],
      "metadata": {
        "id": "K0lFaEMTmIrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_avg_length(word_frq):\n",
        "    total_length = 0\n",
        "    total_words = 0\n",
        "    for word in word_frq:\n",
        "        total_length += len(word) * word_frq[word]\n",
        "        total_words += word_frq[word]\n",
        "    if total_words > 0:\n",
        "        return total_length / total_words\n",
        "    else:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "rU_lO73KOZ5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_length = calc_avg_length(word_frq)\n",
        "print(f\"Average word length: {avg_length:.2f} characters\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZVdf7hsomI4",
        "outputId": "b062f1ab-98d7-4376-8f77-5f7a24062282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average word length: 3.60 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Penn Tree bank tokenization (file/directory)**\n",
        "# Week2_Task1_Apply Penn tree bank Tokenization by file\n",
        "# Week3_Task2_Apply Penn tree bank Tokenization by files in directory\n",
        "\n",
        "# Key Features Handled:\n",
        "\n",
        "\n",
        "*   **Clitics Expansion**: Converts contractions into their full forms for better tokenization.\n",
        "* **Punctuation Splitting**: Handles punctuation separation while preserving special formats like prices and times.\n",
        "* **File/Directory Handling**: Supports processing multiple files in a directory or a single file.\n",
        "* **Word Frequency Analysis**: Provides a count of occurrences for each word/token.\n",
        "* **Tokens and Types Calculation**: Distinguishes between total word instances (tokens) and unique words (types).\n",
        "* **Error Handling**: Handles exceptions for inaccessible files or invalid paths gracefully.\n",
        "* **Google Drive Integration**: Enables accessing files directly from Google Drive for use in Colab."
      ],
      "metadata": {
        "id": "IjZrx7ZrgUSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AQkH67Ge6Br",
        "outputId": "8d6cd7f3-9799-4416-8ea7-8077b5a584f2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JNaIgKSyL_Li"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "def expand_clitics(word):\n",
        "    \"\"\"Expands common clitics into their full forms.\"\"\"\n",
        "    clitic_map = {\n",
        "        \"don't\": [\"do\", \"not\"],\n",
        "        \"isn't\": [\"is\", \"not\"],\n",
        "        \"aren't\": [\"are\", \"not\"],\n",
        "        \"won't\": [\"will\", \"not\"],\n",
        "        \"can't\": [\"can\", \"not\"],\n",
        "        \"didn't\": [\"did\", \"not\"],\n",
        "        \"haven't\": [\"have\", \"not\"],\n",
        "        \"it's\": [\"it\", \"is\"],\n",
        "        \"i'm\": [\"i\", \"am\"],\n",
        "        \"you're\": [\"you\", \"are\"],\n",
        "        \"they're\": [\"they\", \"are\"],\n",
        "        \"there's\": [\"there\", \"is\"],\n",
        "        \"we're\": [\"we\", \"are\"],\n",
        "        \"she's\": [\"she\", \"is\"],\n",
        "        \"he's\": [\"he\", \"is\"],\n",
        "        \"'ve\": [\"have\"],\n",
        "        \"'ll\": [\"will\"],\n",
        "        \"'re\": [\"are\"],\n",
        "        \"'d\": [\"would\"],\n",
        "        \"'s\": [\"is\"],\n",
        "        \"n't\": [\"not\"],\n",
        "        \"they'll\": [\"they\", \"will\"],\n",
        "        \"i'll\": [\"i\", \"will\"],\n",
        "        \"you'll\": [\"you\", \"will\"],\n",
        "        \"we'll\": [\"we\", \"will\"],\n",
        "        \"she'll\": [\"she\", \"will\"],\n",
        "        \"he'll\": [\"he\", \"will\"],\n",
        "        \"doesn't\": [\"does\", \"not\"],\n",
        "        \"wasn't\": [\"was\", \"not\"],\n",
        "        \"weren't\": [\"were\", \"not\"],\n",
        "        \"hasn't\": [\"has\", \"not\"],\n",
        "        \"hadn't\": [\"had\", \"not\"],\n",
        "        \"couldn't\": [\"could\", \"not\"],\n",
        "        \"wouldn't\": [\"would\", \"not\"],\n",
        "        \"shouldn't\": [\"should\", \"not\"],\n",
        "        \"mightn't\": [\"might\", \"not\"],\n",
        "        \"mustn't\": [\"must\", \"not\"],\n",
        "        \"cann't\": [\"can\", \"not\"],\n",
        "        \"let's\": [\"let\", \"us\"]\n",
        "    }\n",
        "    word = word.lower().strip()\n",
        "\n",
        "    if word in clitic_map:\n",
        "        return clitic_map[word]\n",
        "    else:\n",
        "        return [word]  # No clitic, return the word itself\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def handle_puncsplit(text):\n",
        "\n",
        "    exceptions = {\n",
        "        \"p.h.d\": \" PHD \",\n",
        "        \"Dr.\": \" DR \",\n",
        "        \"Mr.\": \" MR \",\n",
        "        \"Mrs.\": \" MRS \",\n",
        "        \"Prof. \": \" PROF \",\n",
        "    }\n",
        "    for exception, placeholder in exceptions.items():\n",
        "        text = re.sub(re.escape(exception), placeholder, text, flags=re.IGNORECASE)\n",
        "\n",
        "    #  Preserve prices (\"$899.99\") and time formats (e.g. \"12:30\")\n",
        "    patterns = re.findall(r\"([$]?\\d+\\.\\d+|\\b\\d{1,2}:\\d{2}\\b)\", text)\n",
        "    for i, price in enumerate(patterns):\n",
        "        text = text.replace(price, f\"PRICE_PLACEHOLDER_{i}\")\n",
        "\n",
        "    text = re.sub(r\"([.,!?;()\\\":])\", r\" \\1 \", text)\n",
        "\n",
        "\n",
        "    for i, price in enumerate(patterns):\n",
        "        text = text.replace(f\"PRICE_PLACEHOLDER_{i}\", price)\n",
        "    for exception, placeholder in exceptions.items():\n",
        "        text = text.replace(placeholder,  exception)\n",
        "\n",
        "    # text->words\n",
        "    words = text.split()\n",
        "\n",
        "    return words\n"
      ],
      "metadata": {
        "id": "TMXfAAbHMh0A"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_norclitics(word):\n",
        "    word = word.lower()\n",
        "    return expand_clitics(word)"
      ],
      "metadata": {
        "id": "hjlj7AkNMj0M"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_frequency(corpus):\n",
        "    word_frq = {}\n",
        "    word_check =[]\n",
        "    for fhand in corpus:\n",
        "        try:\n",
        "            # Read each line from the file handle\n",
        "            for line in fhand:\n",
        "\n",
        "                cleaned_text = line.strip()  # Remove leading/trailing whitespace\n",
        "                words = handle_puncsplit(cleaned_text)\n",
        "\n",
        "                for word in words:\n",
        "                    expanded_words = handle_norclitics(word)\n",
        "                    word_check.append(expanded_words)\n",
        "                    # Count frequency\n",
        "                    for expanded_word in expanded_words:\n",
        "                        if expanded_word in word_frq:\n",
        "                            word_frq[expanded_word] += 1\n",
        "                        else:\n",
        "                            word_frq[expanded_word] = 1\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing file {fhand.name}: {e}\")\n",
        "    return word_frq,word_check"
      ],
      "metadata": {
        "id": "JcU0YOB2MRHs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_tokens_and_types(word_frq):\n",
        "  token = 0\n",
        "  type = 0\n",
        "  for w,f in word_frq.items():\n",
        "    token += f\n",
        "    type += 1\n",
        "\n",
        "  return token, type"
      ],
      "metadata": {
        "id": "zWHSsn7QMadE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_word_frequency(word_frq):\n",
        "    print(f\"{'Word':<20}{'Frequency':<10}\")\n",
        "    print(\"-\" * 30)\n",
        "    for word, frequency in word_frq.items():\n",
        "        print(f\"{word:<20}{frequency:<10}\")"
      ],
      "metadata": {
        "id": "nuLqj1gWMdSl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_corpus(path):\n",
        "    corpus = []\n",
        "\n",
        "    if os.path.isfile(path):\n",
        "        try:\n",
        "            fhand = open(path, \"r\")\n",
        "            corpus.append(fhand)\n",
        "        except Exception as e:\n",
        "            print(f\"Error opening file {path}: {e}\")\n",
        "\n",
        "    elif os.path.isdir(path):\n",
        "        try:\n",
        "            file_names = os.listdir(path)\n",
        "            for file_name in file_names:\n",
        "                file_path = os.path.join(path, file_name)\n",
        "                if os.path.isfile(file_path):\n",
        "                    try:\n",
        "                        fhand = open(file_path, \"r\")\n",
        "                        corpus.append(fhand)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error opening {file_name}: {e}\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"The directory {path} was not found.\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "    else:\n",
        "        print(f\"The path {path} is neither a file nor a directory.\")\n",
        "\n",
        "    return corpus"
      ],
      "metadata": {
        "id": "zYF2wCJJMVbC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main workflow\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# /content/drive/MyDrive/Colab Notebooks/10files\n",
        "# urdu.txt\n",
        "# eng.txt\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    path = input(\"Enter a file or directory path: \")\n",
        "    corpus = create_corpus(path)\n",
        "    if corpus:\n",
        "        word_frq,word_check = get_word_frequency(corpus)\n",
        "        tokens, types = calculate_tokens_and_types(word_frq)\n",
        "\n",
        "        print(\"Tokens: \", tokens)\n",
        "        print(\"Types: \", types)\n",
        "\n",
        "        print(word_check)\n",
        "\n",
        "        print_word_frequency(word_frq)\n",
        "\n",
        "        # Close all file handles\n",
        "        for fhand in corpus:\n",
        "            fhand.close()\n",
        "# /content/drive/MyDrive/Colab Notebooks/10files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-vCAmOzMS6C",
        "outputId": "902871e3-a56f-4ebb-e7cc-a68589c97b08"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Enter a file or directory path: Ngram.txt\n",
            "Tokens:  18\n",
            "Types:  12\n",
            "[['john'], ['read'], ['moby'], ['dick'], ['.'], ['mary'], ['read'], ['a'], ['different'], ['book'], ['.'], ['she'], ['read'], ['a'], ['book'], ['by'], ['cher'], ['.']]\n",
            "Word                Frequency \n",
            "------------------------------\n",
            "john                1         \n",
            "read                3         \n",
            "moby                1         \n",
            "dick                1         \n",
            ".                   3         \n",
            "mary                1         \n",
            "a                   2         \n",
            "different           1         \n",
            "book                2         \n",
            "she                 1         \n",
            "by                  1         \n",
            "cher                1         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week3_Task1_Draw a Possible Tree of sentence themeneatandtheywork\n",
        "\n",
        "## themeneatandtheywork\n",
        "\n",
        "\n",
        "*   the men eat and they work\n",
        "*   the men neat and they work\n",
        "![themeneatandtheywork .png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "cckq31FWi5Hm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week3_Task3_Write an Regular Expression to find all instances of determiner \"the\" in paragraph:"
      ],
      "metadata": {
        "id": "ij6xV95HiuAd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The recent attempt by the police to retain their current rates of pay has not gatheredmuch favour with the southern factions"
      ],
      "metadata": {
        "id": "mgD28FK2ibmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"The recent attempt by the police to retain their current rates of pay has not gathered much favor with the southern factions.\"\n",
        "pattern = r'\\b[Tt][Hh][Ee]\\b'\n",
        "result = re.findall(pattern, text)\n",
        "print(result)\n",
        "#\\b word boundary, ensuring that \"the\" is matched as a complete word and not as part of another word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1S9NeMVjRGt",
        "outputId": "71b5b189-e00d-4a04-f158-292f0e74059d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'the', 'the']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pattern= r'\\bthe\\b'\n"
      ],
      "metadata": {
        "id": "6FaMKmDAke8j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week3_Task4_what Byte Pair Encoding is and how it works\n",
        "## Byte Pair Encoding\n",
        "BPE (Byte Pair Encoding) is a way to split words into smaller pieces so that computers can understand text better. Instead of storing every word, it stores common word parts and builds words from them.\n",
        "\n",
        "## Why use it?\n",
        "* Smaller Dictionary:\n",
        "Instead of storing every whole word, BPE stores common word parts (like \"un\", \"happy\", \"ness\"). This makes the dictionary smaller and models faster.\n",
        "\n",
        "* Understand Rare Words:\n",
        "If a model sees a new or rare word (like \"unhappily\"), it can break it into smaller, known parts (\"un\", \"happy\", \"ly\"). This helps the model understand words it hasn't seen before.\n",
        "\n",
        "## Token learner algorithm\n",
        "\n",
        "* Initialisation:\n",
        " *  Vocabulary V ← unique characters in text\n",
        " * Tokenise text into separate characters\n",
        "*  for iteration i = 1 to K:\n",
        "  * Find most frequent pair of adjacent tokens: tL,tR\n",
        "  * Merge tokens: tnew = tLtR\n",
        "  * Add to vocabulary: V ← V ∪{tnew}\n",
        "  * Replace all occurrences of tL,tR in text with tnew"
      ],
      "metadata": {
        "id": "IW6OnF6waAoz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMcW3nrJyJZ5"
      },
      "outputs": [],
      "source": [
        "def tokenize(text):\n",
        "  text = list(text)\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9QR7wzXyaZR"
      },
      "outputs": [],
      "source": [
        "def vocabulary(text):\n",
        "  text = set(text)\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJ7_GG4g0To0"
      },
      "outputs": [],
      "source": [
        "def frequentpair(text):\n",
        "\n",
        "    dic = {}\n",
        "    pair_components = {}\n",
        "\n",
        "    for i in range(len(text) - 1):\n",
        "        if text[i] != \" \" and text[i + 1] != \" \":\n",
        "            pair = text[i] + text[i + 1]\n",
        "            if pair in dic:\n",
        "                dic[pair] += 1\n",
        "            else:\n",
        "                dic[pair] = 1\n",
        "                pair_components[pair] = (text[i], text[i + 1])\n",
        "\n",
        "    if all(freq == 1 for freq in dic.values()):\n",
        "      return -1,-1\n",
        "\n",
        "    if dic:\n",
        "        most_frequent_pair = max(dic, key=dic.get)\n",
        "        return most_frequent_pair, pair_components[most_frequent_pair]\n",
        "    return -1,-1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_RuVxEc96vz"
      },
      "outputs": [],
      "source": [
        "def mergetltr(token_list,pair):\n",
        "\n",
        "    i = 0\n",
        "\n",
        "    while i < len(token_list) - 1:\n",
        "        if token_list[i] + token_list[i + 1] == pair:\n",
        "            token_list[i] = pair\n",
        "            token_list.pop(i + 1)\n",
        "        else:\n",
        "            i += 1\n",
        "\n",
        "    return token_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oL4OVgLfyDzK"
      },
      "outputs": [],
      "source": [
        "def data():\n",
        "  # text=\"hello hell help held\"\n",
        "  text = \"hugs hug pug pun bun\"\n",
        "  # text = \"banana bandana can cana banana man manly handle sand and sandman\"\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTAMkGxZyjYZ",
        "outputId": "2bff1c2d-4ff9-4d6c-bb1e-0fb44757114c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenize text:  ['h', 'u', 'g', 's', ' ', 'h', 'u', 'g', ' ', 'p', 'u', 'g', ' ', 'p', 'u', 'n', ' ', 'b', 'u', 'n']\n",
            "\n",
            "tl: u \n",
            "tr: g \n",
            "Pair:  ug \n",
            "vocabulary:  {'n', 'u', 'ug', 'g', 'b', 'p', 's', 'h', ' '} \n",
            "Text:  ['h', 'ug', 's', ' ', 'h', 'ug', ' ', 'p', 'ug', ' ', 'p', 'u', 'n', ' ', 'b', 'u', 'n']\n",
            "\n",
            "tl: h \n",
            "tr: ug \n",
            "Pair:  hug \n",
            "vocabulary:  {'n', 'u', 'ug', 'g', 'b', 'p', 'hug', 's', 'h', ' '} \n",
            "Text:  ['hug', 's', ' ', 'hug', ' ', 'p', 'ug', ' ', 'p', 'u', 'n', ' ', 'b', 'u', 'n']\n",
            "\n",
            "tl: u \n",
            "tr: n \n",
            "Pair:  un \n",
            "vocabulary:  {'n', 'u', 'ug', 'g', 'b', 'p', 'hug', 's', 'h', ' ', 'un'} \n",
            "Text:  ['hug', 's', ' ', 'hug', ' ', 'p', 'ug', ' ', 'p', 'un', ' ', 'b', 'un']\n"
          ]
        }
      ],
      "source": [
        "merge=[]\n",
        "text = data()\n",
        "Tokenize_text = tokenize(text)\n",
        "print(\"Tokenize text: \",Tokenize_text)\n",
        "voc = vocabulary(Tokenize_text)\n",
        "new_text=Tokenize_text\n",
        "\n",
        "while (1>0):\n",
        "\n",
        "  pair,pair_token =frequentpair(new_text)\n",
        "\n",
        "  if pair == -1 :\n",
        "    break\n",
        "\n",
        "  voc.add(pair)\n",
        "  merge.append(pair)\n",
        "\n",
        "  tl=pair_token[0]\n",
        "  tr=pair_token[1]\n",
        "\n",
        "  new_text = mergetltr(new_text, pair)\n",
        "\n",
        "  print(\"\\ntl:\",tl,\"\\ntr:\",tr,\"\\nPair: \",pair,\"\\nvocabulary: \",voc,\"\\nText: \" ,new_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Merge pairs: \",merge)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grH5NRUoDMFm",
        "outputId": "654e7313-15db-441a-9eca-e6c44351b021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merge pairs:  ['ug', 'hug', 'un']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_word = \"huged\"\n",
        "# test_word = \"unpug\"\n",
        "# test_word = \"helder\"\n",
        "\n",
        "tokens = tokenize(test_word)\n",
        "for m in merge:\n",
        "  tokens = mergetltr(tokens, m)\n",
        "print(\"Encoded test word:\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxZf4YssSQq8",
        "outputId": "d6f4eecd-9c5b-499c-eb05-9850c992f3ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded test word: ['hug', 'e', 'd']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week3_Task5_ Write a code to print out a unicode for any typed character of any language"
      ],
      "metadata": {
        "id": "UiI1ULVQQ9AC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_unicode_formats():\n",
        "    BOLD = \"\\033[1m\"\n",
        "    RESET = \"\\033[0m\"\n",
        "\n",
        "    print(f\"{BOLD}\\n*** Welcome to the Unicode Info System ***{RESET}\")\n",
        "    char = input(\"\\nEnter a character: \").strip()\n",
        "\n",
        "    if not char:\n",
        "        print(f\"{BOLD} \\nError!: Please enter a valid character.  {RESET}\")\n",
        "        return\n",
        "\n",
        "    unicode = ord(char[0])  # Get Unicode of the first character only\n",
        "\n",
        "    formats = {\n",
        "        \"Decimal\": f\"U+{unicode}\",\n",
        "        \"Uppercase Hex\": f\"U+{unicode:X}\",\n",
        "        \"Lowercase Hex\": f\"U+{unicode:x}\",\n",
        "        \"Binary\": f\"U+{unicode:b}\",\n",
        "        \"Octal\": f\"U+{unicode:o}\"\n",
        "    }\n",
        "\n",
        "# Uses string formatting (ljust) to align the column headers and values, giving it a clean table structure.\n",
        "\n",
        "    print(f\"{BOLD}\\nUnicode in Different Formats:{RESET}\")\n",
        "    print(\"-\" * 45)\n",
        "    print(f\"{BOLD}{'Format'.ljust(20)}{'Unicode Representation'}{RESET}\")\n",
        "    print(\"-\" * 45)\n",
        "\n",
        "    for name, value in formats.items():\n",
        "        print(f\"{name.ljust(20)}{value}\")\n",
        "\n",
        "print_unicode_formats()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDZT19ERRG_A",
        "outputId": "3e23d175-a46c-4459-c06a-87e42fe6ef86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "*** Welcome to the Unicode Info System ***\u001b[0m\n",
            "\n",
            "Enter a character: M\n",
            "\u001b[1m\n",
            "Unicode in Different Formats:\u001b[0m\n",
            "---------------------------------------------\n",
            "\u001b[1mFormat              Unicode Representation\u001b[0m\n",
            "---------------------------------------------\n",
            "Decimal             U+77\n",
            "Uppercase Hex       U+4D\n",
            "Lowercase Hex       U+4d\n",
            "Binary              U+1001101\n",
            "Octal               U+115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week5,6_NGRAM MODEL and Smooth_NGRAM (probabilites save in files.txt)\n",
        "Add marker in corpus(from pen tree bank)"
      ],
      "metadata": {
        "id": "vByInPCMn1_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ADD marker\n",
        "\n",
        "# voc = []\n",
        "# for word, frequency in word_frq.items():\n",
        "#      voc.append(word)\n",
        "# print(voc)\n",
        "def add_marker(word_check):\n",
        "  voc = [\"<s>\"]  # Start marker\n",
        "  i=0\n",
        "  for word in word_check:\n",
        "      if word != list('.'):\n",
        "        voc.append(\" \".join(word))\n",
        "      if word == list('.') or word == list('-') :\n",
        "          voc.append(\"</s>\")\n",
        "          if i!=len(word_check)-1:  # If it's not the last word start next sentence\n",
        "              voc.append(\"<s>\")\n",
        "      i = i+1\n",
        "\n",
        "  print(voc)\n"
      ],
      "metadata": {
        "id": "TWiVsmcXtKaQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Week_5_Implement NGram model to check the probability of sentence"
      ],
      "metadata": {
        "id": "-iHjOVKc5D0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "LtfbQOSYfnIu"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_ngram_probabilities(corpus):\n",
        "    unigram_counts = Counter(corpus)\n",
        "    bigram_counts = Counter(zip(corpus, corpus[1:]))\n",
        "    trigram_counts = Counter(zip(corpus, corpus[1:], corpus[2:]))\n",
        "    total_words = sum(count for word, count in unigram_counts.items() if word not in {\"<s>\", \"</s>\"})\n",
        "\n",
        "    vocab_size = len(unigram_counts) - 2\n",
        "\n",
        "    unigram_prob = {word: (count ) / (total_words ) for word, count in unigram_counts.items()}\n",
        "    bigram_prob = {bigram: (count) / (unigram_counts.get(bigram[0], 0) ) for bigram, count in bigram_counts.items()}\n",
        "    trigram_prob = {trigram: (count ) / (bigram_counts.get((trigram[0], trigram[1]), 0)) for trigram, count in trigram_counts.items()}\n",
        "\n",
        "    return unigram_prob, bigram_prob, trigram_prob, unigram_counts, bigram_counts, trigram_counts, total_words, vocab_size\n"
      ],
      "metadata": {
        "id": "eJzTeDtQfnIv"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_sentence_probability(sentence, unigram_prob, bigram_prob, trigram_prob, unigram_counts, bigram_counts, vocab_size, total_words, smoothing=1):\n",
        "    words = sentence.lower().split()\n",
        "    words = [\"<s>\"] + words + [\"</s>\"]\n",
        "    print(words)\n",
        "    unigram_prob_sentence = 1.0\n",
        "    bigram_prob_sentence = 1.0\n",
        "    trigram_prob_sentence = 1.0\n",
        "\n",
        "    print(\"\\n--- Sentence Probability Calculation ---\")\n",
        "\n",
        "    print(\"\\nUnigram Probabilities:\")\n",
        "    print(f\"{'Word':<15}{'Count':<10}{'Probability':<15}\")\n",
        "    for word in words:\n",
        "        prob = (unigram_counts.get(word, 0) ) / (total_words )\n",
        "        unigram_prob_sentence *= prob\n",
        "        print(f\"{word:<15}{unigram_counts.get(word, 0):<10}{prob:.6f}\")\n",
        "\n",
        "    print(\"\\nBigram Probabilities:\")\n",
        "    print(f\"{'Bigram':<25}{'Count':<10}{'Probability':<15}\")\n",
        "    for i in range(len(words) - 1):\n",
        "\n",
        "        bigram = (words[i], words[i+1])\n",
        "        prob = bigram_prob.get(bigram,0)\n",
        "        bigram_prob_sentence *= prob\n",
        "        print(f\"{bigram[0]} {bigram[1]:<15}{bigram_counts.get(bigram, 0):<10}{prob:.6f}\")\n",
        "\n",
        "    print(\"\\nTrigram Probabilities:\")\n",
        "    print(f\"{'Trigram':<35}{'Count':<10}{'Probability':<15}\")\n",
        "    for i in range(len(words) - 2):\n",
        "        trigram = (words[i], words[i+1], words[i+2])\n",
        "        bigram_key = (words[i], words[i+1])\n",
        "        prob = trigram_prob.get(trigram, 0)\n",
        "        trigram_prob_sentence *= prob\n",
        "        print(f\"{trigram[0]} {trigram[1]} {trigram[2]:<15}{trigram_counts.get(trigram, 0):<10}{prob:.6f}\")\n",
        "\n",
        "    return unigram_prob_sentence, bigram_prob_sentence, trigram_prob_sentence\n",
        "\n",
        "def print_sentence_probabilities(sentence, unigram_prob_sentence, bigram_prob_sentence, trigram_prob_sentence):\n",
        "    print(\"\\n--- Sentence Probabilities ---\")\n",
        "    print(f\"{'Model':<15}{'Probability':<20}\")\n",
        "    print(f\"{'Unigram':<15}{unigram_prob_sentence:.10f}\")\n",
        "    print(f\"{'Bigram':<15}{bigram_prob_sentence:.10f}\")\n",
        "    print(f\"{'Trigram':<15}{trigram_prob_sentence:.10f}\")\n"
      ],
      "metadata": {
        "id": "8jh3pXiqfnIw"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# corpus = [\"books\", \"enhance\", \"your\", \"knowledge\", \"books\", \"are\", \"powerful\", \"tools\"]\n",
        "add_marker(word_check)\n",
        "unigram_prob, bigram_prob, trigram_prob, unigram_counts, bigram_counts, trigram_counts, total_words, vocab_size = generate_ngram_probabilities(voc)\n"
      ],
      "metadata": {
        "id": "ja7g-V76fnIw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6833ab6-d470-4db2-a7c0-4c9ea0355721"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s>', 'john', 'read', 'moby', 'dick', '</s>', '<s>', 'mary', 'read', 'a', 'different', 'book', '</s>', '<s>', 'she', 'read', 'a', 'book', 'by', 'cher', '</s>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Unigram Probabilities ---\")\n",
        "print(f\"{'Word':<15}{'Count':<10}{'Probability':<10}\")\n",
        "for word, prob in unigram_prob.items():\n",
        "  print(f\"{word:<15}{unigram_counts[word]:<10}{prob:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "124dc805-cbb6-42d5-b113-b96f3983fd7e",
        "id": "wGEceNc0fnIx"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Unigram Probabilities ---\n",
            "Word           Count     Probability\n",
            "<s>            3         0.200000\n",
            "john           1         0.066667\n",
            "read           3         0.200000\n",
            "moby           1         0.066667\n",
            "dick           1         0.066667\n",
            "</s>           3         0.200000\n",
            "mary           1         0.066667\n",
            "a              2         0.133333\n",
            "different      1         0.066667\n",
            "book           2         0.133333\n",
            "she            1         0.066667\n",
            "by             1         0.066667\n",
            "cher           1         0.066667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Bigram Probabilities ---\")\n",
        "print(f\"{'Bigram':<25}{'Count':<10}{'Probability':<10}\")\n",
        "\n",
        "bigrams_to_remove = []\n",
        "\n",
        "for bigram, prob in bigram_prob.items():\n",
        "    if bigram[0] != \"</s>\" and bigram[1] != \"<s>\":\n",
        "        print(f\"{bigram[0]} {bigram[1]:<20}{bigram_counts[bigram]:<10}{prob:.6f}\")\n",
        "    else:\n",
        "        bigrams_to_remove.append(bigram)\n",
        "\n",
        "# Remove invalid bigrams after the loop\n",
        "for bigram in bigrams_to_remove:\n",
        "    bigram_prob.pop(bigram)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6656f7df-3b37-408d-d2b0-872f5e1a7bbe",
        "id": "LQ8LjHl6fnIy"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Bigram Probabilities ---\n",
            "Bigram                   Count     Probability\n",
            "<s> john                1         0.333333\n",
            "john read                1         1.000000\n",
            "read moby                1         0.333333\n",
            "moby dick                1         1.000000\n",
            "dick </s>                1         1.000000\n",
            "<s> mary                1         0.333333\n",
            "mary read                1         1.000000\n",
            "read a                   2         0.666667\n",
            "a different           1         0.500000\n",
            "different book                1         1.000000\n",
            "book </s>                1         0.500000\n",
            "<s> she                 1         0.333333\n",
            "she read                1         1.000000\n",
            "a book                1         0.500000\n",
            "book by                  1         0.500000\n",
            "by cher                1         1.000000\n",
            "cher </s>                1         1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Trigram Probabilities ---\")\n",
        "print(f\"{'Trigram':<35}{'Count':<10}{'Probability':<10}\")\n",
        "trigrams_to_remove=[]\n",
        "for trigram, prob in trigram_prob.items():\n",
        "    if not ((trigram[0] == \"</s>\" or trigram[1] == \"<s>\") or (trigram[1] == \"</s>\" or trigram[2] == \"<s>\")):\n",
        "        print(f\"{trigram[0]} {trigram[1]} {trigram[2]:<20}{trigram_counts[trigram]:<10}{prob:.6f}\")\n",
        "    else:\n",
        "        trigrams_to_remove.append(trigram)  # Store invalid trigrams\n",
        "\n",
        "for trigram in trigrams_to_remove:\n",
        "    trigram_prob.pop(trigram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6606e5af-94e6-4de4-d199-c4dad17d957e",
        "id": "ndpoOZKufnI0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Trigram Probabilities ---\n",
            "Trigram                            Count     Probability\n",
            "<s> john read                1         1.000000\n",
            "john read moby                1         1.000000\n",
            "read moby dick                1         1.000000\n",
            "moby dick </s>                1         1.000000\n",
            "<s> mary read                1         1.000000\n",
            "mary read a                   1         1.000000\n",
            "read a different           1         0.500000\n",
            "a different book                1         1.000000\n",
            "different book </s>                1         1.000000\n",
            "<s> she read                1         1.000000\n",
            "she read a                   1         1.000000\n",
            "read a book                1         0.500000\n",
            "a book by                  1         1.000000\n",
            "book by cher                1         1.000000\n",
            "by cher </s>                1         1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_probabilities(filename, data):\n",
        "    with open(filename, \"w\") as file:\n",
        "        for k, v in data.items():\n",
        "            file.write(f\"{str(k):<30} {v:.6f}\\n\")\n",
        "save_probabilities(\"unigram.txt\", unigram_prob)\n",
        "save_probabilities(\"bigram.txt\", bigram_prob)\n",
        "save_probabilities(\"trigram.txt\", trigram_prob)"
      ],
      "metadata": {
        "id": "1DSNg80_fnI1"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"John read a book\"\n",
        "print(\"\\nSentence: \",sentence)\n",
        "unigram_prob_sentence, bigram_prob_sentence, trigram_prob_sentence = compute_sentence_probability(sentence, unigram_prob, bigram_prob, trigram_prob, unigram_counts, bigram_counts, vocab_size, total_words)\n",
        "print_sentence_probabilities(sentence, unigram_prob_sentence, bigram_prob_sentence, trigram_prob_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a61fb0c7-24dc-45c5-b783-3daff41ecd02",
        "id": "Yh7li-qEfnI2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence:  John read a book\n",
            "['<s>', 'john', 'read', 'a', 'book', '</s>']\n",
            "\n",
            "--- Sentence Probability Calculation ---\n",
            "\n",
            "Unigram Probabilities:\n",
            "Word           Count     Probability    \n",
            "<s>            3         0.200000\n",
            "john           1         0.066667\n",
            "read           3         0.200000\n",
            "a              2         0.133333\n",
            "book           2         0.133333\n",
            "</s>           3         0.200000\n",
            "\n",
            "Bigram Probabilities:\n",
            "Bigram                   Count     Probability    \n",
            "<s> john           1         0.333333\n",
            "john read           1         1.000000\n",
            "read a              2         0.666667\n",
            "a book           1         0.500000\n",
            "book </s>           1         0.500000\n",
            "\n",
            "Trigram Probabilities:\n",
            "Trigram                            Count     Probability    \n",
            "<s> john read           1         1.000000\n",
            "john read a              0         0.000000\n",
            "read a book           1         0.500000\n",
            "a book </s>           0         0.000000\n",
            "\n",
            "--- Sentence Probabilities ---\n",
            "Model          Probability         \n",
            "Unigram        0.0000094815\n",
            "Bigram         0.0555555556\n",
            "Trigram        0.0000000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Week_6_Implement NGram model by applying Add one smoothing\n"
      ],
      "metadata": {
        "id": "yXVSW0AxstyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "hziUP85K0pYf"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_ngram_probabilities(corpus, smoothing=1):\n",
        "    unigram_counts = Counter(corpus)\n",
        "    bigram_counts = Counter(zip(corpus, corpus[1:]))\n",
        "    trigram_counts = Counter(zip(corpus, corpus[1:], corpus[2:]))\n",
        "    total_words = sum(count for word, count in unigram_counts.items() if word not in {\"<s>\", \"</s>\"})\n",
        "\n",
        "    vocab_size = len(unigram_counts) - 2\n",
        "    print(\"COUNTS:\",bigram_counts)\n",
        "    unigram_prob = {word: (count + smoothing) / (total_words + smoothing * vocab_size) for word, count in unigram_counts.items()}\n",
        "    bigram_prob = {bigram: (count + smoothing) / (unigram_counts.get(bigram[0], 0) + smoothing * vocab_size) for bigram, count in bigram_counts.items()}\n",
        "    trigram_prob = {trigram: (count + smoothing) / (bigram_counts.get((trigram[0], trigram[1]), 0) + smoothing * vocab_size) for trigram, count in trigram_counts.items()}\n",
        "    print(\"Probabilites:\",bigram_prob)\n",
        "    return unigram_prob, bigram_prob, trigram_prob, unigram_counts, bigram_counts, trigram_counts, total_words, vocab_size\n"
      ],
      "metadata": {
        "id": "XZe7EZ4-0l8a"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_sentence_probability(sentence, unigram_prob, bigram_prob, trigram_prob, unigram_counts, bigram_counts, vocab_size, total_words, smoothing=1):\n",
        "    words = sentence.lower().split()\n",
        "    words = [\"<s>\"] + words + [\"</s>\"]\n",
        "    print(words)\n",
        "    unigram_prob_sentence = 1.0\n",
        "    bigram_prob_sentence = 1.0\n",
        "    trigram_prob_sentence = 1.0\n",
        "\n",
        "    print(\"\\n--- Sentence Probability Calculation ---\")\n",
        "\n",
        "    print(\"\\nUnigram Probabilities:\")\n",
        "    print(f\"{'Word':<15}{'Count':<10}{'Probability':<15}\")\n",
        "    for word in words:\n",
        "        prob = (unigram_counts.get(word, 0) + smoothing) / (total_words + smoothing * vocab_size)\n",
        "        unigram_prob_sentence *= prob\n",
        "        print(f\"{word:<15}{unigram_counts.get(word, 0):<10}{prob:.6f}\")\n",
        "\n",
        "    print(\"\\nBigram Probabilities:\")\n",
        "    print(f\"{'Bigram':<25}{'Count':<10}{'Probability':<15}\")\n",
        "    for i in range(len(words) - 1):\n",
        "        bigram = (words[i], words[i+1])\n",
        "        prob = bigram_prob.get(bigram, (smoothing / (unigram_counts.get(words[i], 0) + smoothing * vocab_size)))\n",
        "        bigram_prob_sentence *= prob\n",
        "        print(f\"{bigram[0]} {bigram[1]:<15}{bigram_counts.get(bigram, 0):<10}{prob:.6f}\")\n",
        "\n",
        "    print(\"\\nTrigram Probabilities:\")\n",
        "    print(f\"{'Trigram':<35}{'Count':<10}{'Probability':<15}\")\n",
        "    for i in range(len(words) - 2):\n",
        "        trigram = (words[i], words[i+1], words[i+2])\n",
        "        bigram_key = (words[i], words[i+1])\n",
        "        prob = trigram_prob.get(trigram, (smoothing / (bigram_counts.get(bigram_key, 0) + smoothing * vocab_size)))\n",
        "        trigram_prob_sentence *= prob\n",
        "        print(f\"{trigram[0]} {trigram[1]} {trigram[2]:<15}{trigram_counts.get(trigram, 0):<10}{prob:.6f}{trigram_prob_sentence:.10f}\")\n",
        "\n",
        "    return unigram_prob_sentence, bigram_prob_sentence, trigram_prob_sentence\n",
        "\n",
        "def print_sentence_probabilities(sentence, unigram_prob_sentence, bigram_prob_sentence, trigram_prob_sentence):\n",
        "    print(\"\\n--- Sentence Probabilities ---\")\n",
        "    print(f\"{'Model':<15}{'Probability':<20}\")\n",
        "    print(f\"{'Unigram':<15}{unigram_prob_sentence:.10f}\")\n",
        "    print(f\"{'Bigram':<15}{bigram_prob_sentence:.10f}\")\n",
        "    print(f\"{'Trigram':<15}{trigram_prob_sentence:.10f}\")\n"
      ],
      "metadata": {
        "id": "AoH84BqH0yoy"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# corpus = [\"books\", \"enhance\", \"your\", \"knowledge\", \"books\", \"are\", \"powerful\", \"tools\"]\n",
        "add_marker(word_check)\n",
        "unigram_prob, bigram_prob, trigram_prob, unigram_counts, bigram_counts, trigram_counts, total_words, vocab_size = generate_ngram_probabilities(voc)\n"
      ],
      "metadata": {
        "id": "Ab1fUhrx01bp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c400fe6d-e1e0-4a31-eb8d-9ea5814b740b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s>', 'john', 'read', 'moby', 'dick', '</s>', '<s>', 'mary', 'read', 'a', 'different', 'book', '</s>', '<s>', 'she', 'read', 'a', 'book', 'by', 'cher', '</s>']\n",
            "COUNTS: Counter({('</s>', '<s>'): 2, ('read', 'a'): 2, ('<s>', 'john'): 1, ('john', 'read'): 1, ('read', 'moby'): 1, ('moby', 'dick'): 1, ('dick', '</s>'): 1, ('<s>', 'mary'): 1, ('mary', 'read'): 1, ('a', 'different'): 1, ('different', 'book'): 1, ('book', '</s>'): 1, ('<s>', 'she'): 1, ('she', 'read'): 1, ('a', 'book'): 1, ('book', 'by'): 1, ('by', 'cher'): 1, ('cher', '</s>'): 1})\n",
            "Probabilites: {('<s>', 'john'): 0.14285714285714285, ('john', 'read'): 0.16666666666666666, ('read', 'moby'): 0.14285714285714285, ('moby', 'dick'): 0.16666666666666666, ('dick', '</s>'): 0.16666666666666666, ('</s>', '<s>'): 0.21428571428571427, ('<s>', 'mary'): 0.14285714285714285, ('mary', 'read'): 0.16666666666666666, ('read', 'a'): 0.21428571428571427, ('a', 'different'): 0.15384615384615385, ('different', 'book'): 0.16666666666666666, ('book', '</s>'): 0.15384615384615385, ('<s>', 'she'): 0.14285714285714285, ('she', 'read'): 0.16666666666666666, ('a', 'book'): 0.15384615384615385, ('book', 'by'): 0.15384615384615385, ('by', 'cher'): 0.16666666666666666, ('cher', '</s>'): 0.16666666666666666}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Unigram Probabilities ---\")\n",
        "print(f\"{'Word':<15}{'Count':<10}{'Probability':<10}\")\n",
        "for word, prob in unigram_prob.items():\n",
        "  print(f\"{word:<15}{unigram_counts[word]:<10}{prob:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wDncWUO0wP_",
        "outputId": "97716b54-9e41-4fb6-9af0-c94f85cd32a2"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Unigram Probabilities ---\n",
            "Word           Count     Probability\n",
            "<s>            3         0.153846\n",
            "john           1         0.076923\n",
            "read           3         0.153846\n",
            "moby           1         0.076923\n",
            "dick           1         0.076923\n",
            "</s>           3         0.153846\n",
            "mary           1         0.076923\n",
            "a              2         0.115385\n",
            "different      1         0.076923\n",
            "book           2         0.115385\n",
            "she            1         0.076923\n",
            "by             1         0.076923\n",
            "cher           1         0.076923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Bigram Probabilities ---\")\n",
        "print(f\"{'Bigram':<25}{'Count':<10}{'Probability':<10}\")\n",
        "\n",
        "# Store bigrams to remove in a list first\n",
        "bigrams_to_remove = []\n",
        "\n",
        "for bigram, prob in bigram_prob.items():\n",
        "    if bigram[0] != \"</s>\" and bigram[1] != \"<s>\":\n",
        "        print(f\"{bigram[0]} {bigram[1]:<20}{bigram_counts[bigram]:<10}{prob:.6f}\")\n",
        "    else:\n",
        "        bigrams_to_remove.append(bigram)  # Store for later removal\n",
        "\n",
        "# Remove invalid bigrams after the loop\n",
        "for bigram in bigrams_to_remove:\n",
        "    bigram_prob.pop(bigram)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VinA6hXV1o_s",
        "outputId": "875bc777-ca12-4ba4-db43-9b2892da90e4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Bigram Probabilities ---\n",
            "Bigram                   Count     Probability\n",
            "<s> john                1         0.142857\n",
            "john read                1         0.166667\n",
            "read moby                1         0.142857\n",
            "moby dick                1         0.166667\n",
            "dick </s>                1         0.166667\n",
            "<s> mary                1         0.142857\n",
            "mary read                1         0.166667\n",
            "read a                   2         0.214286\n",
            "a different           1         0.153846\n",
            "different book                1         0.166667\n",
            "book </s>                1         0.153846\n",
            "<s> she                 1         0.142857\n",
            "she read                1         0.166667\n",
            "a book                1         0.153846\n",
            "book by                  1         0.153846\n",
            "by cher                1         0.166667\n",
            "cher </s>                1         0.166667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Trigram Probabilities ---\")\n",
        "print(f\"{'Trigram':<35}{'Count':<10}{'Probability':<10}\")\n",
        "trigrams_to_remove=[]\n",
        "for trigram, prob in trigram_prob.items():\n",
        "   if not ((trigram[0] == \"</s>\" or trigram[1] == \"<s>\") or (trigram[1] == \"</s>\" or trigram[2] == \"<s>\")):\n",
        "        print(f\"{trigram[0]} {trigram[1]} {trigram[2]:<20}{trigram_counts[trigram]:<10}{prob:.6f}\")\n",
        "   else:\n",
        "        trigrams_to_remove.append(trigram)  # Store invalid trigrams\n",
        "\n",
        "for trigram in trigrams_to_remove:\n",
        "    trigram_prob.pop(trigram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZttBkZU1pVI",
        "outputId": "4ccb2bc0-5e22-4fc9-eac3-b873755709bb"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Trigram Probabilities ---\n",
            "Trigram                            Count     Probability\n",
            "<s> john read                1         0.166667\n",
            "john read moby                1         0.166667\n",
            "read moby dick                1         0.166667\n",
            "moby dick </s>                1         0.166667\n",
            "<s> mary read                1         0.166667\n",
            "mary read a                   1         0.166667\n",
            "read a different           1         0.153846\n",
            "a different book                1         0.166667\n",
            "different book </s>                1         0.166667\n",
            "<s> she read                1         0.166667\n",
            "she read a                   1         0.166667\n",
            "read a book                1         0.153846\n",
            "a book by                  1         0.166667\n",
            "book by cher                1         0.166667\n",
            "by cher </s>                1         0.166667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_probabilities(filename, data):\n",
        "    with open(filename, \"w\") as file:\n",
        "        for k, v in data.items():\n",
        "            file.write(f\"{str(k):<30} {v:.6f}\\n\")\n",
        "save_probabilities(\"smooth_unigram.txt\", unigram_prob)\n",
        "save_probabilities(\"smooth_bigram.txt\", bigram_prob)\n",
        "save_probabilities(\"smooth_trigram.txt\", trigram_prob)"
      ],
      "metadata": {
        "id": "UJqhNMDE5dxV"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"John read a book\"\n",
        "print(\"\\nSentence: \",sentence)\n",
        "unigram_prob_sentence, bigram_prob_sentence, trigram_prob_sentence = compute_sentence_probability(sentence, unigram_prob, bigram_prob, trigram_prob, unigram_counts, bigram_counts, vocab_size, total_words)\n",
        "print_sentence_probabilities(sentence, unigram_prob_sentence, bigram_prob_sentence, trigram_prob_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpC_uFJg07k5",
        "outputId": "f3b59e4f-bfc5-4c90-ec6c-a1731ea2f41c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence:  John read a book\n",
            "['<s>', 'john', 'read', 'a', 'book', '</s>']\n",
            "\n",
            "--- Sentence Probability Calculation ---\n",
            "\n",
            "Unigram Probabilities:\n",
            "Word           Count     Probability    \n",
            "<s>            3         0.153846\n",
            "john           1         0.076923\n",
            "read           3         0.153846\n",
            "a              2         0.115385\n",
            "book           2         0.115385\n",
            "</s>           3         0.153846\n",
            "\n",
            "Bigram Probabilities:\n",
            "Bigram                   Count     Probability    \n",
            "<s> john           1         0.142857\n",
            "john read           1         0.166667\n",
            "read a              2         0.214286\n",
            "a book           1         0.153846\n",
            "book </s>           1         0.153846\n",
            "\n",
            "Trigram Probabilities:\n",
            "Trigram                            Count     Probability    \n",
            "<s> john read           1         0.1666670.1666666667\n",
            "john read a              0         0.0833330.0138888889\n",
            "read a book           1         0.1538460.0021367521\n",
            "a book </s>           0         0.0833330.0001780627\n",
            "\n",
            "--- Sentence Probabilities ---\n",
            "Model          Probability         \n",
            "Unigram        0.0000037292\n",
            "Bigram         0.0001207584\n",
            "Trigram        0.0001780627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nsf8KKFiwJnH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
